{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5eeff3fb6e7a444f82d4bc04616aaace",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8b2a6c725bc443c68199fb1e3a0f4a35",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "cf3aa0c6540c475084fb9fcca4ac2271",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2324,
    "execution_start": 1716902156070,
    "source_hash": "596fb062"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shared-libs/python3.10/py/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib_inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Dataset's Iteration Performance\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# OS\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import string\n",
    "import unicodedata\n",
    "from glob import glob\n",
    "from io import BytesIO\n",
    "from imageio import imread\n",
    "from zipfile import ZipFile\n",
    "import requests, zipfile, io\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "\n",
    "# SciPy\n",
    "from scipy.signal import convolve\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import *\n",
    "from torchvision.ops import nms\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "\n",
    "# IDLMAM Libraries\n",
    "from idlmam import moveTo, run_epoch, set_seed, View\n",
    "from idlmam import train_simple_network, set_seed, Flatten, weight_reset, train_network\n",
    "from idlmam import LanguageNameDataset, pad_and_pack, EmbeddingPackable, LastTimeStep, LambdaLayer\n",
    "\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#  IPython Display\n",
    "from IPython.display import Latex\n",
    "from IPython.display import display_pdf\n",
    "from IPython.display import set_matplotlib_formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5385e2f19be04e19a31140bc77e9695c",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 20,
      "type": "marks"
     }
    ]
   },
   "source": [
    "### Visualization Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "65c759726baa4adaa12a5651431c4dc9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 110,
    "execution_start": 1716902161664,
    "source_hash": "54d23ce7"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('png', 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8696ccca57594d9c837cb653de50d0c8",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "italic": true
      },
      "toCodePoint": 13,
      "type": "marks"
     }
    ]
   },
   "source": [
    "### Setting Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "ecbb565863db45feabf6468ea4aa4f93",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 168,
    "execution_start": 1716902164359,
    "source_hash": "e2815cc8"
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "ffa65782d49f4e4a86533d69b66b2e26",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 88,
    "execution_start": 1716902165927,
    "source_hash": "8756bf76"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1bd8dc65b59946eca25b97b10a65635d",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Nuclei Detection: Retrieving & Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "a0d41f5675bb41e49091b97a146c305b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 218,
    "execution_start": 1716902201117,
    "source_hash": "6e8cf0de"
   },
   "outputs": [],
   "source": [
    "data_url_zip = \"https://github.com/kamalkraj/DATA-SCIENCE-BOWL-2018/blob/master/data/stage1_train.zip?raw=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c519cd2b3e604363858a3996ee7e6448",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1716902240607,
    "source_hash": "ed051f66"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Extract The Data\n",
    "if not os.path.isdir('./data/stage1_train'):\n",
    "    resp = urlopen(data_url_zip)\n",
    "    os.makedirs(\"./data/stage1_train\", exist_ok=True)\n",
    "    zipfile = ZipFile(BytesIO(resp.read()))\n",
    "    zipfile.extractall(path = './data/stage1_train')\n",
    "\n",
    "# Get All The Image Paths\n",
    "paths = glob(\"./data/stage1_train/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9fb5ba19a8b24f458c46dfc232857750",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 34,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### Nuclei's Dataset Class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1f3448e2b92a4f36a611ce7f8582afc7",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "class DSB2018(Dataset):\n",
    "    def __init__(self, paths):\n",
    "        self.paths = paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):   \n",
    "        img_path = glob(self.paths[idx] + \"/images/*\")[0]        \n",
    "        mask_imgs = glob(self.paths[idx] + \"/masks/*\")        \n",
    "        img = imread(img_path)[:,:,0:3]\n",
    "        img = np.moveaxis(img, -1, 0)\n",
    "        img = img/255.0\n",
    "       \n",
    "        masks = [imread(f)/255.0 for f in mask_imgs]\n",
    "        \n",
    "        final_mask = np.zeros(masks[0].shape)\n",
    "        for m in masks:\n",
    "            final_mask = np.logical_or(final_mask, m)\n",
    "        final_mask = final_mask.astype(np.float32)\n",
    "        \n",
    "        img, final_mask = torch.tensor(img), torch.tensor(final_mask).unsqueeze(0) \n",
    "        img = F.interpolate(img.unsqueeze(0), (256, 256))\n",
    "        final_mask = F.interpolate(final_mask.unsqueeze(0), (256, 256))\n",
    "        return img.type(torch.FloatTensor)[0], final_mask.type(torch.FloatTensor)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a4f782c900e345fa8c207caeeeb876cc",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Create the Dataset class object\n",
    "dsb_data = DSB2018(paths)\n",
    "\n",
    "# Original Image\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "# Mask Image\n",
    "plt.imshow(dsb_data[0][0].permute(1,2,0).numpy())\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.imshow(dsb_data[0][1].numpy()[0,:], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "904de0d775e24d289f5a22677328e50b",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Plotting 2nd Image\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "# 2nd Mask\n",
    "plt.imshow(dsb_data[1][0].permute(1,2,0).numpy())\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.imshow(dsb_data[1][1].numpy()[0,:], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "15d149245d134e3fa048d40e1189cf3b",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 20,
      "type": "marks"
     }
    ]
   },
   "source": [
    "### Train-Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "55aa65502ed94d97b0616b633cba49f3",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Training Set\n",
    "train_split, test_split = torch.utils.data.random_split(dsb_data, [500, len(dsb_data)-500])\n",
    "\n",
    "# Training Loader\n",
    "train_seg_loader = DataLoader(train_split, batch_size=16, shuffle=True)\n",
    "\n",
    "# Test Loader\n",
    "test_seg_loader = DataLoader(test_split,  batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9672b0a5dff446b3827eb244452545ff",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Channels - (RGB)\n",
    "C = 3 \n",
    "\n",
    "# Filters\n",
    "n_filters = 32 \n",
    "\n",
    "# Loss Function\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "18195897d8684505adc5a250b12e5850",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 30,
      "type": "marks"
     }
    ]
   },
   "source": [
    "### 1st Image Segmentation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "55ba17189b434222a6a11eaf77644baa",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# CNN Hidden Layers Helper Function:\n",
    "def cnnLayer(in_filters, out_filters, kernel_size=3):\n",
    "    padding = kernel_size//2\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_filters, out_filters, kernel_size, padding=padding), \n",
    "        nn.BatchNorm2d(out_filters),\n",
    "        nn.LeakyReLU(), \n",
    "    )\n",
    "\n",
    "segmentation_model = nn.Sequential(\n",
    "    cnnLayer(C, n_filters), \n",
    "    *[cnnLayer(n_filters, n_filters) for _ in range(5)], \n",
    "    nn.Conv2d(n_filters, 1, (3,3), padding=1), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a0ec44fbf8ba4d54bd500381f24c1b2c",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 28,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### Segmentation Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ca154a71f23640c885776ae5fa335902",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Segmentation Model Training\n",
    "seg_results = train_network(segmentation_model, \n",
    "loss_func, \n",
    "train_seg_loader, \n",
    "epochs=10, \n",
    "device=device, \n",
    "val_loader=test_seg_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "54b54951e35341228e1a9dbb2bc8390b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 40,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### Checking the model's outcome as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a79e00deed3747099b82a9e7330699a2",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "index = 6 \n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = segmentation_model(test_split[index][0].unsqueeze(0).to(device))[0].cpu()\n",
    "    pred = torch.sigmoid(logits) >= 0.5\n",
    "\n",
    "# Plotting: Input, Ground Truth & Prediction\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.subplot(1, 3, 1)\n",
    "\n",
    "plt.imshow(test_split[index][0].permute(1,2,0).numpy(), cmap='gray') \n",
    "plt.subplot(1, 3, 2)\n",
    "\n",
    "plt.imshow(test_split[index][1].numpy()[0,:], cmap='gray') \n",
    "plt.subplot(1, 3, 3) \n",
    "\n",
    "plt.imshow(pred.numpy()[0,:], cmap='gray') \n",
    "\n",
    "plt.annotate('Error: Hole', color=\"red\", fontsize=20, xy=(130, 230),\n",
    "            xycoords='data', xytext=(-60, 60),\n",
    "            textcoords='offset points',\n",
    "            arrowprops=dict(arrowstyle=\"->\",\n",
    "                            linewidth = 2.5,\n",
    "                            color = 'tomato')\n",
    "            )\n",
    "\n",
    "plt.annotate('Error: Hole', color=\"red\", fontsize=20, xy=(210, 75),\n",
    "            xycoords='data', xytext=(-160, -60),\n",
    "            textcoords='offset points',\n",
    "            arrowprops=dict(arrowstyle=\"->\",\n",
    "                            linewidth = 2.5,\n",
    "                            color = 'tomato')\n",
    "            )\n",
    "plt.annotate('Error: Phantom object', color=\"red\", fontsize=20, xy=(247, 15),\n",
    "            xycoords='data', xytext=(-240, -50),\n",
    "            textcoords='offset points',\n",
    "            arrowprops=dict(arrowstyle=\"->\",\n",
    "                            linewidth = 2.5,\n",
    "                            color = 'tomato')\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a100a98607fb4a33955e5f3b0b419925",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 48,
      "type": "marks"
     }
    ]
   },
   "source": [
    "## Transposed Convolutions for Expanding Image Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "018fd885343647f39c91e4ecd1722c67",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 51,
      "type": "marks"
     }
    ]
   },
   "source": [
    "### Implementing a Network with Transposed Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "02c7279f5b7546d9b35b769175622344",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "segmentation_model2 = nn.Sequential(\n",
    "    cnnLayer(C, n_filters), \n",
    "    cnnLayer(n_filters, n_filters),\n",
    "    nn.MaxPool2d(2), \n",
    "    cnnLayer(n_filters, 2*n_filters),\n",
    "    cnnLayer(2*n_filters, 2*n_filters),\n",
    "    cnnLayer(2*n_filters, 2*n_filters),\n",
    "    nn.ConvTranspose2d(2*n_filters, n_filters, (3,3), padding=1, output_padding=1, stride=2),\n",
    "    nn.BatchNorm2d(n_filters),\n",
    "    nn.LeakyReLU(),\n",
    "    cnnLayer(n_filters, n_filters),\n",
    "    nn.Conv2d(n_filters, 1, (3,3), padding=1), #Shape is now (B, 1, W, H)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ae78b3b5d014454cbabcb265d624b0d6",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 26,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### Transposed Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "12d6f6355d204d83976fbf143c9734f6",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "seg_results2 = train_network(segmentation_model2, \n",
    "loss_func, \n",
    "train_seg_loader, \n",
    "epochs=10, \n",
    "device=device, \n",
    "val_loader=test_seg_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5016c01cce724826859a5e3fcc29abc3",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 32,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### Contrasting Outcomes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "01756557b7a547e59996624c75bb06bf",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "index = 6 \n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = segmentation_model2(test_split[index][0].unsqueeze(0).to(device))[0].cpu()\n",
    "    pred = torch.sigmoid(pred) >= 0.5\n",
    "\n",
    "\n",
    "# Plotting: Input, Ground Truth & Prediction\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.subplot(1, 3, 1)\n",
    "\n",
    "# Original Plotting\n",
    "plt.imshow(test_split[index][0].permute(1,2,0).numpy(), cmap='gray')  #\n",
    "plt.subplot(1, 3, 2)\n",
    "\n",
    "# Ground Truth\n",
    "plt.imshow(test_split[index][1].numpy()[0,:], cmap='gray') \n",
    "plt.subplot(1, 3, 3)\n",
    "\n",
    "# Prediction\n",
    "plt.imshow(pred.numpy()[0,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1ecde01b93944830bac158e71c8080e4",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "del segmentation_model\n",
    "del segmentation_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6c548dc96d584fc8ab355887c00c4b82",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# CNN Model Results\n",
    "sns.lineplot(x='epoch', \n",
    "y='val loss', \n",
    "data=seg_results, \n",
    "label='CNN')\n",
    "\n",
    "# CNN with Transposed-Conv Model Results\n",
    "sns.lineplot(x='epoch', \n",
    "y='val loss', \n",
    "data=seg_results2, \n",
    "label='CNN w/ transposed-conv')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "58d0bb33b709489db1679275e9619b2b",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 39,
      "type": "marks"
     }
    ]
   },
   "source": [
    "## U-Net: Looking at Fine & Coarse Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b547f7f6efce44f8b10caef90017bd4d",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 18,
      "type": "marks"
     }
    ]
   },
   "source": [
    "### Implementing U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "bb071b316b5f48b08028276857e72cde",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "class UNetBlock2d(nn.Module): \n",
    "    def __init__(self, in_channels, mid_channels, out_channels=None, layers=1, sub_network=None, filter_size=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        in_layers = [cnnLayer(in_channels, mid_channels, filter_size)]\n",
    "        \n",
    "        if sub_network is None:\n",
    "            inputs_to_outputs = 1\n",
    "        else:\n",
    "            inputs_to_outputs = 2\n",
    "\n",
    "        out_layers = [ cnnLayer(mid_channels*inputs_to_outputs, mid_channels, filter_size)]\n",
    "        \n",
    "        for _ in range(layers-1):\n",
    "            in_layers.append(cnnLayer(mid_channels, mid_channels, filter_size))\n",
    "            out_layers.append(cnnLayer(mid_channels, mid_channels, filter_size))\n",
    "        if out_channels is not None:\n",
    "            out_layers.append(nn.Conv2d(mid_channels, out_channels, 1, padding=0))\n",
    "    \n",
    "        self.in_model = nn.Sequential(*in_layers)\n",
    "        if sub_network is not None:\n",
    "            self.bottleneck = nn.Sequential(\n",
    "                nn.MaxPool2d(2), \n",
    "                sub_network, \n",
    "                nn.ConvTranspose2d(mid_channels, mid_channels, filter_size, padding=filter_size//2, output_padding=1, stride=2)\n",
    "            )\n",
    "        else:\n",
    "            self.bottleneck = None\n",
    "        self.out_model = nn.Sequential(*out_layers)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        full_scale_result = self.in_model(x) \n",
    "        if self.bottleneck is not None:\n",
    "            bottle_result = self.bottleneck(full_scale_result)\n",
    "            full_scale_result = torch.cat([full_scale_result, bottle_result], dim=1)\n",
    "        return self.out_model(full_scale_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d1dd2f92068f4582b6f4c737cdf104fd",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 23,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### U-Net Model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "345b1301305c4afa8ed87a395aedf639",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "unet_model = nn.Sequential(\n",
    "    UNetBlock2d(3, 32, layers=2, sub_network=\n",
    "        UNetBlock2d(32, 64, out_channels=32, layers=2, sub_network=\n",
    "            UNetBlock2d(64, 128, out_channels=64, layers=2)\n",
    "        ),\n",
    "    ),\n",
    "    \n",
    "    nn.Conv2d(32, 1, (3,3), padding=1), #Shape is now (B, 1, W, H)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d72fca104fba4bea99da6228d1fdbf1f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 20,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### U-Net Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a6d90a7c106646ca87d3cdfe18feb5fe",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "unet_results = train_network(unet_model, \n",
    "loss_func, \n",
    "train_seg_loader, \n",
    "epochs=10, \n",
    "device=device, \n",
    "val_loader=test_seg_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8e88492aeeb04cf689cabfa066d336b9",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# CNN Model Results\n",
    "sns.lineplot(x='epoch', y='val loss', data=seg_results, label='CNN')\n",
    "\n",
    "# CNN with Transposed-Conv Model Results\n",
    "sns.lineplot(x='epoch', y='val loss', data=seg_results2, label='CNN w/ transposed-conv')\n",
    "\n",
    "# U-Net Model Results\n",
    "sns.lineplot(x='epoch', y='val loss', data=unet_results, label='UNet')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2366d999877e4e04ac4ec685a3d14414",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 36,
      "type": "marks"
     }
    ]
   },
   "source": [
    "## Object Detection with Bounding Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e6db0ca293bf46c8aff89c906b62eae2",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 12,
      "type": "marks"
     }
    ]
   },
   "source": [
    "### Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "793623d5a3b64f279d552cb2f4e4bf92",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 8,
      "type": "marks"
     }
    ]
   },
   "source": [
    "- Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d9382bf61b0b41168b102de528a6b1f2",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 24,
      "type": "marks"
     },
     {
      "fromCodePoint": 24,
      "marks": {
       "bold": true
      },
      "toCodePoint": 29,
      "type": "marks"
     }
    ]
   },
   "source": [
    "- Region Proposal Network (RPN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1a3a1830934244d3b3562b22c6bb7e14",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 18,
      "type": "marks"
     },
     {
      "fromCodePoint": 18,
      "marks": {
       "bold": true
      },
      "toCodePoint": 25,
      "type": "marks"
     },
     {
      "fromCodePoint": 25,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 32,
      "type": "marks"
     }
    ]
   },
   "source": [
    "- Region of Interest (ROI) Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8b8e999a62114cdab2e3ca4c45c718cb",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 29,
      "type": "marks"
     }
    ]
   },
   "source": [
    "### Using Faster R-CNN in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "11c5a888a4cc40799e25207cce26649e",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Setting Special Seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c8905484ac4046ce94efae13567d7499",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "class Class2Detect(Dataset):\n",
    "    def __init__(self, dataset, toSample=3, canvas_size=100):\n",
    "        self.dataset = dataset\n",
    "        self.toSample = toSample\n",
    "        self.canvas_size = canvas_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        final_size = self.canvas_size\n",
    "        img_p = torch.zeros((final_size,final_size), dtype=torch.float32)\n",
    "        for _ in range(np.random.randint(1,self.toSample+1)):\n",
    "            \n",
    "            img, label = self.dataset[np.random.randint(0,len(self.dataset))]\n",
    "            _, img_h, img_w = img.shape\n",
    "            offsets = np.random.randint(0,final_size-np.max(img.shape),size=(4))\n",
    "            offsets[1] = final_size - img.shape[1] - offsets[0]\n",
    "            offsets[3] = final_size - img.shape[2] - offsets[2]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                img_p = img_p + F.pad(img, tuple(offsets))\n",
    "            \n",
    "            xmin = offsets[0]\n",
    "            xmax = offsets[0]+img_w\n",
    "            ymin = offsets[2]\n",
    "            ymax = offsets[2]+img_h\n",
    "            boxes.append( [xmin, ymin, xmax, ymax] )\n",
    "            labels.append( label )\n",
    "\n",
    "            \n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        return img_p, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b164834d12814f61ab49c12779b0b25c",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 37,
      "type": "marks"
     }
    ]
   },
   "source": [
    "Implementing a R-CNN Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a914735b3b9a4c7694e53bdba647ea6f",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Train Set\n",
    "train_data = Class2Detect(torchvision.datasets.MNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True))\n",
    "\n",
    "# Test Set\n",
    "test_data = Class2Detect(torchvision.datasets.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "59648f7623934bb8ae5d04f7dfa01190",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for img, label in batch:\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "bee78a2a1cfa4d8ba3a13810f967706b",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, \n",
    "batch_size=128, \n",
    "shuffle=True, \n",
    "collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6b7cc2c97cf244cd959e8268a6e58d14",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 34,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### Examining The MNIST Detection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "60b9ae7571ad43058310ad245c1518db",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "x, y = train_data[0] \n",
    "\n",
    "imshow(x.numpy()[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0653d73e9311463290dde4014cd5f74c",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "print(y) \n",
    "print(\"Boxes: \", y['boxes']) \n",
    "print(\"Labels: \", y['labels']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e234695a07f94d4da92a7d320145f087",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 29,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### Defining a Faster R-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "72ee954d9d2e42f0aef81430aaf45fd5",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Channels\n",
    "C = 1\n",
    "\n",
    "# Classes\n",
    "classes = 10\n",
    "\n",
    "# Backbone Filters\n",
    "n_filters = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "c996d7742e054906a0630cb714df1e1f",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "backbone = nn.Sequential(\n",
    "    cnnLayer(C, n_filters),    \n",
    "    cnnLayer(n_filters, n_filters),\n",
    "    cnnLayer(n_filters, n_filters),\n",
    "    nn.MaxPool2d((2,2)),\n",
    "    cnnLayer(n_filters, 2*n_filters),\n",
    "    cnnLayer(2*n_filters, 2*n_filters),\n",
    "    cnnLayer(2*n_filters, 2*n_filters),\n",
    "    nn.MaxPool2d((2,2)),\n",
    "    cnnLayer(2*n_filters, 4*n_filters),\n",
    "    cnnLayer(4*n_filters, 4*n_filters),\n",
    ")\n",
    "\n",
    "# Backbone Output R-CNN Channels\n",
    "backbone.out_channels = n_filters*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f49b94222d9d42fcb6bb7bfcf444fa1e",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Anchor Generator\n",
    "anchor_generator = AnchorGenerator(sizes=((32),), aspect_ratios=((1.0),)) \n",
    "\n",
    "# Backbone's Feature Map\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'], output_size=7, sampling_ratio=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b498598bdf9b43e8a803dbd8b93aebe2",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 16,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### Model's Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e4334d2cabac4f43baeaa6c35c728d28",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "model = FasterRCNN(backbone, \n",
    "num_classes=10, \n",
    "image_mean = [0.5], \n",
    "image_std = [0.229], \n",
    "min_size=100, \n",
    "max_size=100, \n",
    "rpn_anchor_generator=anchor_generator, \n",
    "box_roi_pool=roi_pooler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1208d43f9e2941fca3187d30edae9cad",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 41,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### Implementing a Faster R-CNN Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4c08f357d42b479489fcee8f78de7cf9",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "model = model.train()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "for epoch in tqdm(range(1), desc=\"Epoch\", disable=False):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tqdm(train_loader, desc=\"Train Batch\", leave=False, disable=False):\n",
    "        inputs = moveTo(inputs, device)\n",
    "        labels = moveTo(labels, device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses = model(inputs, labels)\n",
    "        loss = 0\n",
    "        for partial_loss in losses.values():\n",
    "            loss += partial_loss\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "05ebb46b9ea14dcd80a09546738a57d3",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "d94b1202fe694f01a3e471ae2e96f4d5",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "set_seed(161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e3322a9508354a8a8436550e4c1d3bb7",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "x, y = test_data[0]\n",
    "\n",
    "# Ideal Ground Truth Outcome\n",
    "print(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "166eca9edc85463da91c16e1991c97eb",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model([x.to(device)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d616f603e3224dc78024692b3aa81d68",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 21,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### Examining The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cb9580b5361441abb3ba0afd93916c62",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5623b340a3d4436da70c2bc7a0e161c6",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def plotDetection(ax, abs_pos, label=None):\n",
    "    x1, y1, x2, y2 = abs_pos\n",
    "    rect = patches.Rectangle((x1,y1),x2-x1,y2-y1,linewidth=1,edgecolor='r',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    if label is not None:\n",
    "        plt.text(x1+0.5, y1, label, color='black', bbox=dict(facecolor='white', edgecolor='white', pad=1.0))\n",
    "    \n",
    "    return \n",
    "\n",
    "def showPreds(img, pred):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(img.cpu().numpy()[0,:])\n",
    "    boxes = pred['boxes'].cpu()\n",
    "    labels = pred['labels'].cpu()\n",
    "    scores = pred['scores'].cpu()\n",
    "    \n",
    "    num_preds = labels.shape[0]\n",
    "    for i in range(num_preds):\n",
    "        plotDetection(ax, boxes[i].cpu().numpy(), label=str(labels[i].item()))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2032d645665f4cff9a82a57756f05ca8",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "showPreds(x, pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a883c5a06dc74902b65e7c2011171470",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "ShowPreds outcome has shown spurious overlapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1df905960a094dbba8316421a40e3257",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 29,
      "type": "marks"
     }
    ]
   },
   "source": [
    "### Suppressing Overlapping Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d4aa95b2935c4cd5bed2d62ad6717194",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 12,
      "type": "marks"
     },
     {
      "fromCodePoint": 12,
      "marks": {
       "bold": true
      },
      "toCodePoint": 29,
      "type": "marks"
     }
    ]
   },
   "source": [
    "- Non-Maximum Suppression (NMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0ce54d9121314a7695b658f6d7b8f938",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 23,
      "type": "marks"
     },
     {
      "fromCodePoint": 23,
      "marks": {
       "bold": true
      },
      "toCodePoint": 29,
      "type": "marks"
     }
    ]
   },
   "source": [
    "- Intersection over Union (IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4f586d23205f4464857007a22cc2a192",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "print(pred[0]['boxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cccf479bfc5946ed96d6016b8ec02a27",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "print(pred[0]['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2a9d54ec59d74d038d217858a7149132",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "print(nms(pred[0]['boxes'], pred[0]['scores'], 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "bf1e3c6123124a528bfabb914e66310f",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def showPreds(img, pred, iou_max_overlap=0.5, min_score=0.05, label_names=None):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    img = img.cpu().numpy()\n",
    "    if img.shape[0] == 1:\n",
    "        ax.imshow(img[0,:])\n",
    "    else:\n",
    "        ax.imshow(np.moveaxis(img, 0, 2))\n",
    "    boxes = pred['boxes'].cpu()\n",
    "    labels = pred['labels'].cpu()\n",
    "    scores = pred['scores'].cpu()\n",
    "    \n",
    "    selected = nms(boxes, scores, iou_max_overlap).cpu().numpy()\n",
    "    \n",
    "    for i in selected:\n",
    "        if scores[i].item() > min_score:\n",
    "            if label_names is None:\n",
    "                label = str(labels[i].item())\n",
    "            else:\n",
    "                label = label_names[labels[i].item()]\n",
    "            plotDetection(ax, boxes[i].cpu().numpy(), label=label)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "91c4dca7f8c248e688ddd33dbee0d91d",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 33,
      "type": "marks"
     }
    ]
   },
   "source": [
    "## Using The Pretrained Faster R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "3499c8bdd08e4a2e93e15fc10d1ddd52",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "rcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ed5b3f1891c44b299a47a1b2acbaaacf",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "rcnn = rcnn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0c9791f448354786a1ee4dba12e96cf2",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "italic": true
      },
      "toCodePoint": 28,
      "type": "marks"
     }
    ]
   },
   "source": [
    "##### COCO Instance Category Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ded5dd613b0e45148e0264290280be1d",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "NAME = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "58992323375a4dd79fb6a4928faf8bb0",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/10best-cars-group-cropped-1542126037.jpg\",\n",
    "    \"https://miro.medium.com/max/5686/1*ZqJFvYiS5GmLajfUfyzFQA.jpeg\",\n",
    "    \"https://www.denverpost.com/wp-content/uploads/2018/03/virginia_umbc_001.jpg?w=910\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "941dc317fb9642db8c9e16272a01a7f9",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "response = requests.get(urls[0])\n",
    "img = Image.open(BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b1344189cf1c473894974ec71a0a8156",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "img = np.asarray(img)/256.0\n",
    "img = torch.tensor(img, dtype=torch.float32).permute((2,0,1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = rcnn([img]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8fce57d771bb4932a79ed20a9f123db2",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "showPreds(img, pred[0], iou_max_overlap=0.15, min_score=0.15, label_names=NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=2fe63438-cd94-4397-bd67-8cd5a8e03d33' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "dba657cbbbac4d7b99e2bd528777a225",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
