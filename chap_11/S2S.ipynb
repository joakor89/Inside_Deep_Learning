{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"7518278a8b3841efbe22ef7ec47b8ce6","deepnote_cell_type":"text-cell-h1"},"source":"# Sequence to Sequence","block_group":"ba20ccdab30e463a8532ace13da3c3a9"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":17,"fromCodePoint":0}],"cell_id":"7faa30ffc9604be8b1ca05033fd657d7","deepnote_cell_type":"text-cell-h2"},"source":"## Loading Libraries","block_group":"e75f1376e5974eeba007afeccdc0bc3f"},{"cell_type":"code","metadata":{"source_hash":"1a25f21e","execution_start":1717346031634,"execution_millis":2202,"deepnote_to_be_reexecuted":false,"cell_id":"58c9335c863c4b81844ebc2bb44f25cc","deepnote_cell_type":"code"},"source":"# Numerical Computing\nimport numpy as np\n\n# Data Manipulation\nimport pandas as pd\n\n# Data Visualization\nimport seaborn as sns\nimport matplotlib\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport matplotlib.patches as patches\n\n# Dataset's Iteration Performance\nfrom tqdm import tqdm\n\n# Time\nimport time\n\n# OS\nimport re\nimport sys\nimport json\nimport string\nimport unicodedata\nfrom glob import glob\nfrom io import BytesIO\nfrom imageio import imread\nfrom zipfile import ZipFile\nimport requests, zipfile, io\nfrom urllib.request import urlopen\n\n\n\n# SciPy\nfrom scipy.signal import convolve\n\n# PyTorch\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import *\nfrom torchvision.ops import nms\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\n\n\n# IDLMAM Libraries\nfrom idlmam import moveTo, run_epoch, set_seed, View, pad_and_pack\nfrom idlmam import train_simple_network, set_seed, Flatten, weight_reset, train_network\nfrom idlmam import LanguageNameDataset, pad_and_pack, EmbeddingPackable, LastTimeStep, LambdaLayer\nfrom idlmam import AttentionAvg, GeneralScore, DotScore, AdditiveAttentionScore, ApplyAttention, getMaskByFill\n\n\n# Scikit-Learn\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\n#  IPython Display\nfrom IPython.display import Latex\nfrom IPython.display import display_pdf\nfrom IPython.display import set_matplotlib_formats","block_group":"58c9335c863c4b81844ebc2bb44f25cc","execution_count":1,"outputs":[{"name":"stderr","text":"/shared-libs/python3.10/py/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/shared-libs/python3.10/py/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/a73263cc-c3ea-43a1-9cc0-67c2e4ca0d4d","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":20,"fromCodePoint":0}],"cell_id":"e2884d418a53413daa38dceee8bc5822","deepnote_cell_type":"text-cell-h3"},"source":"### Visualization Set-Up","block_group":"23cca9be93d44899a2cc8326bc8a513a"},{"cell_type":"code","metadata":{"source_hash":"54d23ce7","execution_start":1717346033846,"execution_millis":72,"deepnote_to_be_reexecuted":false,"cell_id":"d7dd8c2042b34780a90d3a09616e38da","deepnote_cell_type":"code"},"source":"%matplotlib inline\n\nmatplotlib_inline.backend_inline.set_matplotlib_formats('png', 'pdf')","block_group":"b2edf306d9314c27a37b40b0dd86d813","execution_count":2,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":13,"fromCodePoint":0}],"cell_id":"15d9a5e44c5547c6a83877f386ebbf52","deepnote_cell_type":"text-cell-h3"},"source":"### Setting Seeds","block_group":"273be74cbfe84215ace5cea9e2b79c6a"},{"cell_type":"code","metadata":{"source_hash":"e2815cc8","execution_start":1717346033850,"execution_millis":105,"deepnote_to_be_reexecuted":false,"cell_id":"09c6200eec90432ea737a33639246c1d","deepnote_cell_type":"code"},"source":"torch.backends.cudnn.deterministic=True\n\nset_seed(42)","block_group":"575379d3c8bf4726b77c0aa82012da29","execution_count":3,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"8756bf76","execution_start":1717346034040,"execution_millis":79,"deepnote_to_be_reexecuted":false,"cell_id":"ac6d7973c522468d9bf3f5bb6fc97536","deepnote_cell_type":"code"},"source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","block_group":"99b6aca02e3f4e9ea4627e2307eb37b9","execution_count":4,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":55,"fromCodePoint":0}],"cell_id":"a8503bc695a54a8eb545f51e806e7bf6","deepnote_cell_type":"text-cell-h2"},"source":"## Sequence-to-Sequence as a Kind of Denoising AutoEncoder","block_group":"8779f0b4da914539af9f8532b5db5a94"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":44,"fromCodePoint":0}],"cell_id":"e08f14f0e9eb4107b23bae021537bcd0","deepnote_cell_type":"text-cell-h3"},"source":"### Loading Data: A Small English-French Dataset","block_group":"aa61abb9fa1347cd882fa9063321a858"},{"cell_type":"code","metadata":{"source_hash":"f1f520c4","execution_start":1717346034041,"execution_millis":78,"deepnote_to_be_reexecuted":false,"cell_id":"03aa2945c0cc4aba95ea138eb6f38b7c","deepnote_cell_type":"code"},"source":"# Batch Size\nB = 128\n\n# Epochs\nepochs = 10","block_group":"478e137e397f457ca790951b51877326","execution_count":5,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"3b21a99d","execution_start":1717346034042,"execution_millis":928,"deepnote_to_be_reexecuted":false,"cell_id":"95ee34c78f7e4169bb9e5168c2fa3a03","deepnote_cell_type":"code"},"source":"all_data = []\n\nresp = urlopen(\"https://download.pytorch.org/tutorial/data.zip\")\n\nzipfile = ZipFile(BytesIO(resp.read()))\n\nfor line in zipfile.open(\"data/eng-fra.txt\").readlines():\n    line = line.decode('utf-8').lower()\n    line = re.sub(r\"[-.!?]+\", r\" \", line)\n    source_lang, target_lang = line.split(\"\\t\")[0:2]\n    all_data.append( (source_lang.strip(), target_lang.strip()) ) ","block_group":"e77f74bb2f8d44c5bc979bce2fe5512e","execution_count":6,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"9f2c91fc","execution_start":1717346034974,"execution_millis":44,"deepnote_to_be_reexecuted":false,"cell_id":"0e10494378594ad8b225db23c674f1ec","deepnote_cell_type":"code"},"source":"for i in range(10):\n    print(all_data[i])","block_group":"016bc3e292e04d928af4e80fcac0b8cd","execution_count":7,"outputs":[{"name":"stdout","text":"('go', 'va')\n('run', 'cours')\n('run', 'courez')\n('wow', 'ça alors')\n('fire', 'au feu')\n('help', \"à l'aide\")\n('jump', 'saute')\n('stop', 'ça suffit')\n('stop', 'stop')\n('stop', 'arrête toi')\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/1302f0db-532b-456b-baed-5f07cbd7083c","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"533afa10","execution_start":1717346035005,"execution_millis":155,"deepnote_to_be_reexecuted":false,"cell_id":"6ae2a8f98fc44d9fa66853a296660615","deepnote_cell_type":"code"},"source":"short_subset = [] \n\nMAX_LEN = 6\n\nfor (s, t) in all_data:\n    if max(len(s.split(\" \")), len(t.split(\" \"))) <= MAX_LEN:\n        short_subset.append((s,t))\n\nprint(\"Using \", len(short_subset), \"/\", len(all_data))","block_group":"d5462647d31f4509801c804edb3d0315","execution_count":8,"outputs":[{"name":"stdout","text":"Using  66251 / 135842\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/16d94143-d666-4d03-9f1e-e4235e5550e1","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":22,"fromCodePoint":0}],"cell_id":"6fd73116bd9244f59fbd37c8847182c9","deepnote_cell_type":"text-cell-p"},"source":"Building The Alphabet:","block_group":"e2a1bbe2c3ce49b3a8f97a81395d33ba"},{"cell_type":"code","metadata":{"source_hash":"eeecebed","execution_start":1717346035212,"execution_millis":133,"deepnote_to_be_reexecuted":false,"cell_id":"2764c9a7cfdf48b8b7eb93b8abebc809","deepnote_cell_type":"code"},"source":"SOS_token = \"<SOS>\"\n\nEOS_token = \"<EOS>\" \n\nPAD_token = \"_PADDING_\"\n\nword2indx = {PAD_token:0, SOS_token:1, EOS_token:2}\nfor s, t in short_subset:\n    for sentance in (s, t):\n        for word in sentance.split(\" \"):\n            if word not in word2indx:\n                word2indx[word] = len(word2indx)\n\nprint(\"Size of Vocab: \", len(word2indx))\n\n\nindx2word = {}\n\nfor word, indx in word2indx.items():\n    indx2word[indx] = word","block_group":"8cc1de6c3eae467fab9abe2850d614b2","execution_count":9,"outputs":[{"name":"stdout","text":"Size of Vocab:  24577\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/fae165be-0432-4412-9f9a-d8207a0a2108","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":35,"fromCodePoint":0}],"cell_id":"e8475d7f7e84416f8ebd63f8b787d3f5","deepnote_cell_type":"text-cell-p"},"source":"Implementing a Translation Dataset:","block_group":"1a727028062a4fd299d99b9421794be5"},{"cell_type":"code","metadata":{"source_hash":"18cef090","execution_start":1717346035396,"execution_millis":38,"deepnote_to_be_reexecuted":false,"cell_id":"b68ec1605b3941369ef0af0ca0a5c230","deepnote_cell_type":"code"},"source":"class TranslationDataset(Dataset):\n\n    def __init__(self, lang_pairs, word2indx):\n        self.lang_pairs = lang_pairs\n        self.word2indx = word2indx\n\n    def __len__(self):\n        return len(self.lang_pairs)\n\n    def __getitem__(self, idx):\n        x, y = self.lang_pairs[idx]\n        x = SOS_token + \" \" + x + \" \" + EOS_token\n        y = y + \" \" + EOS_token\n        \n        x = [self.word2indx[w] for w in x.split(\" \")]\n        y = [self.word2indx[w] for w in y.split(\" \")]\n        \n        x = torch.tensor(x, dtype=torch.int64)\n        y = torch.tensor(y, dtype=torch.int64)\n        \n        return x, y\n\nbigdataset = TranslationDataset(short_subset, word2indx)","block_group":"36e78f05b9704f69bcda170c7cf16ca7","execution_count":10,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":53,"fromCodePoint":0}],"cell_id":"5f6b487ad6fa456591bad0eaa03b19bc","deepnote_cell_type":"text-cell-p"},"source":"Implementing a Collate Function for Translation Data:","block_group":"f78686dbcb3a4912ad47befa255deaa6"},{"cell_type":"code","metadata":{"source_hash":"d9bd0b75","execution_start":1717346035397,"execution_millis":98,"deepnote_to_be_reexecuted":false,"cell_id":"2b8f067bed60436ebb657aaf5de9dbe6","deepnote_cell_type":"code"},"source":"set_seed(42)","block_group":"df82bd05ab94425fb68d7aa339d1bc77","execution_count":11,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"507ce921","execution_start":1717346035499,"execution_millis":20,"deepnote_to_be_reexecuted":false,"cell_id":"d3374ab51ed8408b8d75b27c6913afea","deepnote_cell_type":"code"},"source":"train_size = round(len(bigdataset)*0.9)\n\ntest_size = len(bigdataset)-train_size\n\ntrain_dataset, test_dataset = torch.utils.data.random_split(bigdataset, [train_size, test_size])","block_group":"c0c4e648cc8647ed9835993e756eddfc","execution_count":12,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"993e54ae","execution_start":1717346035549,"execution_millis":95,"deepnote_to_be_reexecuted":false,"cell_id":"ebbea43d8461402f85f49927ed422c05","deepnote_cell_type":"code"},"source":"def pad_batch(batch):\n    max_x = max([i[0].size(0) for i in batch])\n    max_y = max([i[1].size(0) for i in batch])\n    \n    PAD = word2indx[PAD_token]\n    \n    X = [F.pad(i[0], (0,max_x-i[0].size(0)), value=PAD) for i in batch]\n    Y = [F.pad(i[1], (0,max_y-i[1].size(0)), value=PAD) for i in batch]\n    \n    X, Y = torch.stack(X), torch.stack(Y)\n    \n    return (X, Y), Y","block_group":"bc6580ddbb124a4d9325a3f16eec9758","execution_count":13,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"c580b05f","execution_start":1717346035550,"execution_millis":94,"deepnote_to_be_reexecuted":false,"cell_id":"7c1ed68972d946f184605b0ae8bd201c","deepnote_cell_type":"code"},"source":"# Data Loader\ntrain_loader = DataLoader(train_dataset, batch_size=B, shuffle=True, collate_fn=pad_batch)\n\ntest_loader = DataLoader(test_dataset, batch_size=B, collate_fn=pad_batch)","block_group":"7ca494e1787d4127a1392653915eff6e","execution_count":14,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":22,"fromCodePoint":0}],"cell_id":"3c7ceacd37874cdb85c49cbe5f5362ea","deepnote_cell_type":"text-cell-h2"},"source":"## Seq2Seq with Attention","block_group":"92869eecc8264b87bace3b5b72d2b266"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":20,"fromCodePoint":0}],"cell_id":"d6b21b5ebe664e0a8e457d052b80f9a8","deepnote_cell_type":"text-cell-h3"},"source":"### Implementing Seq2Seq","block_group":"722760569d6147f189eb0e7a94919ce8"},{"cell_type":"code","metadata":{"source_hash":"30197e3d","execution_start":1717346035550,"execution_millis":94,"deepnote_to_be_reexecuted":false,"cell_id":"0f6f80ad59b24f758c4f76ab8a654faf","deepnote_cell_type":"code"},"source":"class Seq2SeqAttention(nn.Module):\n\n    def __init__(self, num_embeddings, embd_size, hidden_size, padding_idx=None, layers=1, max_decode_length=20):\n        super(Seq2SeqAttention, self).__init__()\n        self.padding_idx = padding_idx\n        self.hidden_size = hidden_size\n        self.embd = nn.Embedding(num_embeddings, embd_size, padding_idx=padding_idx)\n        \n        self.encode_layers = nn.GRU(input_size=embd_size, hidden_size=hidden_size//2, \n                                       num_layers=layers, bidirectional=True)\n\n        self.decode_layers = nn.ModuleList([nn.GRUCell(embd_size, hidden_size)] + \n                                     [nn.GRUCell(hidden_size, hidden_size) for i in range(layers-1)])\n        self.score_net = DotScore(hidden_size)\n        \n        self.predict_word = nn.Sequential(\n            nn.Linear(2*hidden_size, hidden_size),\n            nn.LeakyReLU(),\n            nn.LayerNorm(hidden_size),\n            nn.Linear(hidden_size, hidden_size),\n            nn.LeakyReLU(),\n            nn.LayerNorm(hidden_size),\n            nn.Linear(hidden_size, num_embeddings)\n        )\n        self.max_decode_length = max_decode_length\n        self.apply_attn = ApplyAttention()\n    \n    def forward(self, input):\n        if isinstance(input, tuple):\n            input, target = input\n        else:\n            target = None\n        B = input.size(0)\n        T = input.size(1)\n\n        x = self.embd(input) \n\n        device = x.device\n\n        mask = getMaskByFill(x)\n\n        seq_lengths = mask.sum(dim=1).view(-1) \n        x_packed = pack_padded_sequence(x, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n        h_encoded, h_last = self.encode_layers(x_packed)\n        h_encoded, _ = pad_packed_sequence(h_encoded) \n        h_encoded = h_encoded.view(B, T, -1) \n\n        hidden_size = h_encoded.size(2) \n        h_last = h_last.view(-1, 2, B, hidden_size//2)[-1,:,:,:] \n        h_last = h_last.permute(1, 0, 2).reshape(B, -1)\n        h_prevs = [h_last for l in range(len(self.decode_layers))]\n\n        all_attentions = []\n        all_predictions = []\n\n        decoder_input = self.embd(input.gather(1,seq_lengths.view(-1,1)-1).flatten()) \n\n        steps = min(self.max_decode_length, T)\n        if target is not None: \n            steps = target.size(1)\n        \n        teacher_forcing = np.random.choice((True,False))\n        for t in range(steps):\n            x_in = decoder_input \n\n            for l in range(len(self.decode_layers)):\n                h_prev = h_prevs[l] \n                h = self.decode_layers[l](x_in, h_prev)\n\n                h_prevs[l] = h\n                x_in = h\n            h_decoder = x_in \n\n            scores = self.score_net(h_encoded, h_decoder) \n            context, weights = self.apply_attn(h_encoded, scores, mask=mask)\n\n            all_attentions.append( weights.detach() ) \n            word_pred = torch.cat((context, h_decoder), dim=1) \n            word_pred = self.predict_word(word_pred) \n            all_predictions.append(word_pred)\n    \n            with torch.no_grad():\n                if self.training:\n                    if target is not None and teacher_forcing:\n                        next_words = target[:,t].squeeze()\n                    else:\n                        next_words = torch.multinomial(F.softmax(word_pred, dim=1), 1)[:,-1]\n                else:\n                    next_words = torch.argmax(word_pred, dim=1)\n            \n            decoder_input = self.embd(next_words.to(device))\n    \n        if self.training: \n            return torch.stack(all_predictions, dim=1)\n        else:\n            return torch.stack(all_predictions, dim=1), torch.stack(all_attentions, dim=1).squeeze()","block_group":"ec7e2dccadf44919862c54d14f1e4fdb","execution_count":15,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":22,"fromCodePoint":0}],"cell_id":"9f9fb96debf64cb59e753d24b05fcb0b","deepnote_cell_type":"text-cell-h3"},"source":"### Training & Evaluation ","block_group":"2d8f067e6cc2423aa137aebc9d9ff0c4"},{"cell_type":"code","metadata":{"source_hash":"d9bd0b75","execution_start":1717346035566,"execution_millis":120,"deepnote_to_be_reexecuted":false,"cell_id":"d4f2c01493824bd9a506d3628fd4324e","deepnote_cell_type":"code"},"source":"set_seed(42)","block_group":"886c613b14024f7fac13d94f71b7542c","execution_count":16,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"9edcf1ba","execution_start":1717346035567,"execution_millis":119,"deepnote_to_be_reexecuted":false,"cell_id":"386f7334bd0841b0b8a6a3c05242c7a0","deepnote_cell_type":"code"},"source":"epochs = 20\n\nseq2seq = Seq2SeqAttention(len(word2indx), 64, 256, \npadding_idx=word2indx[PAD_token], \nlayers=3, \nmax_decode_length=MAX_LEN+2)\n\nfor p in seq2seq.parameters():\n    p.register_hook(lambda grad: torch.clamp(grad, -10, 10))","block_group":"c4a5a3c32b884b12950916ed1d2a7c4c","execution_count":17,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":14,"fromCodePoint":0}],"cell_id":"0a1aac7435af4a44ac9b36370cf8c8ba","deepnote_cell_type":"text-cell-p"},"source":"Loss Function:","block_group":"6ef1b7397c8a4f4da7ae468f338f225b"},{"cell_type":"code","metadata":{"source_hash":"68664000","execution_start":1717346035732,"execution_millis":121,"deepnote_to_be_reexecuted":false,"cell_id":"86a9259fdc7d49c4998337a36d5bcae3","deepnote_cell_type":"code"},"source":"def CrossEntLossTime(x, y):\n    if isinstance(x, tuple):\n        x, _ = x\n    cel = nn.CrossEntropyLoss(ignore_index=word2indx[PAD_token])\n    T = min(x.size(1), y.size(1))\n    \n    loss = 0\n    for t in range(T):\n        loss += cel(x[:,t,:], y[:,t])\n    return loss","block_group":"9c34aa0f91d546358b51d5be9eabe9dd","execution_count":18,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"da2c4d2f","execution_start":1717346076822,"execution_millis":341,"deepnote_to_be_reexecuted":false,"cell_id":"25ee30c46a8a4f3fa1361dfe8813ddbd","deepnote_cell_type":"code"},"source":"# seq2seq_results = train_network(seq2seq, \n# CrossEntLossTime, \n# train_loader, \n# epochs=epochs, \n# device=device)","block_group":"e77edd58d1fd485395ac923cd4306360","execution_count":20,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"70f9774f","execution_start":1717346080372,"execution_millis":76,"deepnote_to_be_reexecuted":false,"cell_id":"53f6c0ad0f334b389161d01fd854e730","deepnote_cell_type":"code"},"source":"sns.lineplot(x='epoch', y='train loss', data=seq2seq_results, label='Seq2Seq')\n\nplt.grid(True)\nplt.show()","block_group":"6d8159cb87bb42908ae731a08dde1db2","execution_count":21,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":33,"fromCodePoint":0}],"cell_id":"45d499b90ade44459e7f89dd9f70cc10","deepnote_cell_type":"text-cell-p"},"source":"Visualizing Attention Score Maps:","block_group":"bac4ab24eb8c445d9482a52881e28aaa"},{"cell_type":"code","metadata":{"source_hash":"78419dc8","execution_start":1717346089589,"execution_millis":79,"deepnote_to_be_reexecuted":false,"cell_id":"a2b25878a3fe4bb9a96d274d9fd2f986","deepnote_cell_type":"code"},"source":"def plot_heatmap(src, trg, scores):\n    fig, ax = plt.subplots()\n    heatmap = ax.pcolor(scores, cmap='gray')\n\n    ax.set_xticklabels(trg, minor=False, rotation='vertical')\n    ax.set_yticklabels(src, minor=False)\n    ax.xaxis.tick_top()\n    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n    ax.invert_yaxis()\n\n    plt.colorbar(heatmap)\n    plt.show()","block_group":"e6510e5a746f4f9289fd92f3caa93449","execution_count":22,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":38,"fromCodePoint":0}],"cell_id":"d8c5dcc6fcf642f4bd5a78342769159a","deepnote_cell_type":"text-cell-p"},"source":"Sequence to Sequence Model Evaluation:","block_group":"921c693d7709468b8c1611a21896a0e3"},{"cell_type":"code","metadata":{"source_hash":"94823c48","execution_start":1717346096180,"execution_millis":10,"deepnote_to_be_reexecuted":false,"cell_id":"ad09c1bcf6774dd394d7933fa639a6de","deepnote_cell_type":"code"},"source":"seq2seq = seq2seq.eval().cpu()\n\ndef results(indx):\n    eng_x, french_y = test_dataset[indx]\n    eng_str = \" \".join([indx2word[i] for i in eng_x.cpu().numpy()])\n    french_str = \" \".join([indx2word[i] for i in french_y.cpu().numpy()])\n    print(\"Input:     \", eng_str)\n    print(\"Target:    \", french_str)\n    \n    with torch.no_grad():\n        preds, attention = seq2seq(eng_x.unsqueeze(0))\n        p = torch.argmax(preds, dim=2)\n    pred_str = \" \".join([indx2word[i] for i in p[0,:].cpu().numpy()])\n    print(\"Predicted: \", pred_str)\n    plot_heatmap(eng_str.split(\" \"), pred_str.split(\" \"), attention.T.cpu().numpy())","block_group":"8e77f82b723f4f67af3fceb4b19631f3","execution_count":23,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"6c2084dd","execution_start":1717346102679,"execution_millis":37,"deepnote_to_be_reexecuted":false,"cell_id":"5b3a4f8370dd416a93782f67c2908538","deepnote_cell_type":"code"},"source":"results(12) ","block_group":"624062482858409aa04ab33b7d2cbada","execution_count":24,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"8064acd1","execution_start":1717346104903,"execution_millis":52,"deepnote_to_be_reexecuted":false,"cell_id":"dfedcfb2ddc74c138d4c241025c75902","deepnote_cell_type":"code"},"source":"results(13) ","block_group":"0f8ec6ee408648348c9f4c0582f3ee7b","execution_count":25,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"383d77f3","execution_start":1717346107236,"execution_millis":71,"deepnote_to_be_reexecuted":false,"cell_id":"c1e9f1e357424fbca5ac0fb59c07dc1c","deepnote_cell_type":"code"},"source":"results(16) ","block_group":"bc300bc14c0e4b6bb528ac9c13d97180","execution_count":26,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=5ce069ec-7808-4ddd-a8a7-20abad0ac4e2' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2024-06-02T00:00:21.497Z"},"deepnote_notebook_id":"12f8ff890f8b49c0bf37b7fd39d71f65","deepnote_execution_queue":[]}}