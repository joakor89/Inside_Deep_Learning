{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d83dd9d3bc7a4ea4bfe8d869dc42d27e","deepnote_cell_type":"text-cell-h1"},"source":"# Network Design Alternative to RNN's","block_group":"309ba581cec1431092ec939f32cb274c"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":17,"fromCodePoint":0}],"cell_id":"dcc104846aa8457abf83a8daf868e1d0","deepnote_cell_type":"text-cell-h2"},"source":"## Loading Libraries","block_group":"8cfdb66a57e54682abf9f109edbbad00"},{"cell_type":"code","metadata":{"source_hash":"c2f69fcf","execution_start":1717437634096,"execution_millis":209,"deepnote_to_be_reexecuted":false,"cell_id":"3014f84fa2994ab999737bd9c912d6b0","deepnote_cell_type":"code"},"source":"#Numerical Computing\nimport numpy as np\n\n# Data Manipulation\nimport pandas as pd\n\n# Data Visualization\nimport seaborn as sns\nimport matplotlib\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport matplotlib.patches as patches\n\n# Dataset's Iteration Performance\nfrom tqdm import tqdm\n\n# Time\nimport time\n\n# OS\nimport re\nimport sys\nimport json\nimport string\nimport unicodedata\nfrom glob import glob\nfrom io import BytesIO\nfrom imageio import imread\nfrom zipfile import ZipFile\nimport requests, zipfile, io\nfrom collections import Counter \nfrom urllib.request import urlopen\n\n\n# SciPy\nfrom scipy.signal import convolve\n\n# PyTorch\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import *\nfrom torchvision.ops import nms\nimport torch.nn.functional as F\nfrom torchtext.vocab import Vocab \nfrom torchvision import transforms\nfrom torchtext.datasets import AG_NEWS\nfrom torchtext.data.utils import get_tokenizer\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\n\n\n# IDLMAM Libraries\nfrom idlmam import moveTo, run_epoch, set_seed, View, pad_and_pack\nfrom idlmam import train_simple_network, set_seed, Flatten, weight_reset, train_network\nfrom idlmam import LanguageNameDataset, pad_and_pack, EmbeddingPackable, LastTimeStep, LambdaLayer\nfrom idlmam import AttentionAvg, GeneralScore, DotScore, AdditiveAttentionScore, ApplyAttention, getMaskByFill\n\n\n# Scikit-Learn\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\n#  IPython Display\nfrom IPython.display import Latex\nfrom IPython.display import display_pdf\nfrom IPython.display import set_matplotlib_formats","block_group":"3014f84fa2994ab999737bd9c912d6b0","execution_count":9,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":20,"fromCodePoint":0}],"cell_id":"b81840f1ca084b55a3ac8f0f5fdf9e2b","deepnote_cell_type":"text-cell-h3"},"source":"### Visualization Set-Up","block_group":"e58262bdbbc648b9b7c923ff6781ff83"},{"cell_type":"code","metadata":{"cell_id":"a8738f128d2549798d854ed90d3ff8a9","deepnote_cell_type":"code"},"source":"%matplotlib inline\n\nmatplotlib_inline.backend_inline.set_matplotlib_formats('png', 'pdf')","block_group":"2708bb4e2c454b8cafdc368cb43a2a37","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":22,"fromCodePoint":0}],"cell_id":"360d14996c0846ebb327c6712a640ed9","deepnote_cell_type":"text-cell-h3"},"source":"### Setting Seeds & Device","block_group":"32ce818cd95543d0a1e16043dfd3cac2"},{"cell_type":"code","metadata":{"cell_id":"d5c9c2bc172442adb2cc958cbc045217","deepnote_cell_type":"code"},"source":"torch.backends.cudnn.deterministic=True\n\nset_seed(42)\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")  ","block_group":"60a5380275594b62a97187e666217d54","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":25,"fromCodePoint":0}],"cell_id":"896446229d834909bed5ec36776f2180","deepnote_cell_type":"text-cell-h2"},"source":"## TorchText: Tools for Text","block_group":"2a020d6150d54c8f829b60a2a12b72e9"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":20,"fromCodePoint":0}],"cell_id":"f80fa3e20e034bf4b592a00cb2413aaf","deepnote_cell_type":"text-cell-h3"},"source":"### Installing ToxchText","block_group":"eb2ad6233fe4404583b41de550d4e707"},{"cell_type":"code","metadata":{"cell_id":"5b8d5cff1b9a4fd1abef8f6231b09dc6","deepnote_cell_type":"code"},"source":"# !pip install  torchtext \n# !pip install  sentencepiece ","block_group":"dde88fbf91c94b308b864c32aeefd179","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":28,"fromCodePoint":0}],"cell_id":"2cd220e0c0f3442c9705751add7de563","deepnote_cell_type":"text-cell-h3"},"source":"### Loading Dataset in TorchText","block_group":"d3a6e8afc9504ec7b99f666309453a3a"},{"cell_type":"code","metadata":{"cell_id":"aa74b32f00ad46049d1a1392ec19236e","deepnote_cell_type":"code"},"source":"# Retrieving Dataset\ntrain_iter, test_iter = AG_NEWS(root='./data', split=('train', 'test'))\n\n# Training Set\ntrain_dataset = list(train_iter)\n\n# Test Set\ntest_dataset = list(test_iter)","block_group":"981bd0f98efe4ec0a633d7c3ab61d7c7","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"68b05c522773492cbcf5f6111408dcdf","deepnote_cell_type":"code"},"source":"# \ntokenizer = get_tokenizer('basic_english')\n\ncounter = Counter() \n\nfor (label, line) in train_dataset: \n    counter.update(tokenizer(line)) \n\nvocab = Vocab(counter, min_freq=10, specials=('<unk>', '<BOS>', '<EOS>', '<PAD>')) \n","block_group":"c3d7136f38bb44f8b8b969a912c5bd28","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"2e503c210ecd4ded9fb2606a9001e062","deepnote_cell_type":"code"},"source":"def text_transform(x): \n    return [vocab['<BOS>']] + [vocab[token] for token in tokenizer(x)] + [vocab['<EOS>']] \n\ndef label_transform(x): \n    return x-1 \n\nprint(text_transform(train_dataset[0][1])) ","block_group":"a4acdf91af2645f1a25c2c61c1d728b3","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"cd671096fd1f47ada435e55308173a33","deepnote_cell_type":"code"},"source":"VOCAB_SIZE = len(vocab)\n\nNUM_CLASS = len(np.unique([z[0] for z in train_dataset])) \n\nprint(\"Vocab: \", VOCAB_SIZE)\nprint(\"Num Classes: \", NUM_CLASS)\n\npadding_idx = vocab[\"<PAD>\"]\n\n# Embedding Dimension\nembed_dim = 128\n\n# Batch Size\nB = 64\n\n# Epochs\nepochs = 15","block_group":"753101cee6a74446acd82ee3c83b3475","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"42bec3b685554560b33457f5b1c4b42d","deepnote_cell_type":"code"},"source":"def pad_batch(batch):\n    labels = [label_transform(z[0]) for z in batch] \n    texts = [torch.tensor(text_transform(z[1]), dtype=torch.int64) for z in batch] \n    \n    max_len = max([text.size(0) for text in texts])\n    texts = [F.pad(text, (0,max_len-text.size(0)), value=padding_idx) for text in texts]\n    x, y = torch.stack(texts), torch.tensor(labels, dtype=torch.int64)\n    \n    return x, y","block_group":"5f5dc622738c4681a19d0862b61ea8df","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"3de3bc975af4423fb066f65fcaf0f0ac","deepnote_cell_type":"code"},"source":"# Data Loader\ntrain_loader = DataLoader(train_dataset, batch_size=B, shuffle=True, collate_fn=pad_batch)\n\ntest_loader = DataLoader(test_dataset, batch_size=B, collate_fn=pad_batch)","block_group":"5265a9691bdd42d280f2b62044f074ce","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":25,"fromCodePoint":0}],"cell_id":"acbe3250f0724761ae940b7ae19aacad","deepnote_cell_type":"text-cell-h2"},"source":"## Defining a Baseline Model","block_group":"9971ff3724ee45569a419458d7965bac"},{"cell_type":"code","metadata":{"cell_id":"72589d951ba34b1aa7262f74dba88701","deepnote_cell_type":"code"},"source":"gru = nn.Sequential(\n  nn.Embedding(VOCAB_SIZE, embed_dim, padding_idx=padding_idx), \n  nn.GRU(embed_dim, embed_dim, num_layers=3, batch_first=True, bidirectional=True), \n  LastTimeStep(rnn_layers=3, bidirectional=True), \n  nn.Linear(embed_dim*2, NUM_CLASS), \n)\n\n# Loss Function\nloss_func = nn.CrossEntropyLoss()","block_group":"82c8e9092262409ebbf6c155676bf23d","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"b0bd63d408d044e8b2d0f7b2388b3e29","deepnote_cell_type":"code"},"source":"gru_results = train_network(gru, \nloss_func, \ntrain_loader, \nval_loader=test_loader, \nscore_funcs={'Accuracy': accuracy_score}, \ndevice=device, \nepochs=epochs)","block_group":"d594a45f3edf41a1af07081c7afde69c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"917530f903194fc7b817ef81a0261ef6","deepnote_cell_type":"code"},"source":"sns.lineplot(x='epoch', \ny='val Accuracy', \ndata=gru_results, \nlabel='GRU')\n\nplt.grid(True)\nplt.show()","block_group":"b1b6fa10d80148da83fc74e3846b61ae","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"3ab5abc0ec424bf68bc00cec3be04f88","deepnote_cell_type":"code"},"source":"simpleEmbdAvg = nn.Sequential(\n    nn.Embedding(VOCAB_SIZE, embed_dim, padding_idx=padding_idx), #(B, T) -> (B, T, D) \n    nn.Linear(embed_dim, embed_dim),\n    nn.LeakyReLU(),\n    nn.Linear(embed_dim, embed_dim),\n    nn.LeakyReLU(),\n    nn.Linear(embed_dim, embed_dim),\n    nn.LeakyReLU(),\n    nn.AdaptiveAvgPool2d((1,embed_dim)), #(B, T, D) -> (B, 1, D)\n    nn.Flatten(), #(B, 1, D) -> (B, D)\n    nn.Linear(embed_dim, embed_dim),\n    nn.LeakyReLU(),\n    nn.BatchNorm1d(embed_dim),\n    nn.Linear(embed_dim, NUM_CLASS)\n)","block_group":"79ea696a14eb45929a360ebdf94d9047","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"6a4eec4016f348f587c1aa31c8af7ed4","deepnote_cell_type":"code"},"source":"simpleEmbdAvg_results = train_network(simpleEmbdAvg, \nloss_func, \ntrain_loader, \nval_loader=test_loader, \nscore_funcs={'Accuracy': accuracy_score}, \ndevice=device, \nepochs=epochs)","block_group":"3ac1b487571b4dfcb6d08aa32736ce2f","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"03070bd1ef7d4ad1969498cd51b0523d","deepnote_cell_type":"code"},"source":"# GRU\nsns.lineplot(x='epoch', \ny='val Accuracy', \ndata=gru_results, \nlabel='GRU')\n\n#\nsns.lineplot(x='epoch', \ny='val Accuracy', \ndata=simpleEmbdAvg_results, \nlabel='Average Embedding')\n\nplt.grid(True)\nplt.show()","block_group":"af93a29855bf436892a3f065503fb7ea","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"5d5328f69657498ab65a7d2a98973684","deepnote_cell_type":"code"},"source":"#\nsns.lineplot(x='total time', \ny='val Accuracy', \ndata=gru_results, \nlabel='GRU')\n\n#\nsns.lineplot(x='total time', \ny='val Accuracy', \ndata=simpleEmbdAvg_results, \nlabel='Average Embedding')\n\nplt.grid(True)\nplt.show()","block_group":"b06a4de0a1a14d6a832d15c7ad83059b","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":41,"fromCodePoint":0}],"cell_id":"3ab53f4f463f4a1999a84d12cf592f50","deepnote_cell_type":"text-cell-h3"},"source":"### Weighted Average over Time with Attention","block_group":"25c92e0b660447d9a27659d73a3ffea2"},{"cell_type":"code","metadata":{"cell_id":"717f26cb1d92452686ac723b9c5d6626","deepnote_cell_type":"code"},"source":"class EmbeddingAttentionBag(nn.Module):\n\n    def __init__(self, vocab_size, D, embd_layers=3, padding_idx=None):\n        super(EmbeddingAttentionBag, self).__init__()\n        self.padding_idx = padding_idx\n        self.embd = nn.Embedding(vocab_size, D, padding_idx=padding_idx)\n        if isinstance(embd_layers, int):\n            self.embd_layers =  nn.Sequential( \n                *[nn.Sequential(nn.Linear(embed_dim, embed_dim),\n                nn.LeakyReLU()) for _ in range(embd_layers)]\n            )\n        else:\n            self.embd_layers = embd_layers\n        self.attn = AttentionAvg(AdditiveAttentionScore(D)) \n    \n    def forward(self, input):\n        if self.padding_idx is not None:\n            mask = input != self.padding_idx\n        else:\n            mask = input == input \n        \n        x = self.embd(input) \n        x = self.embd_layers(x)\n        context = x.sum(dim=1)/(mask.sum(dim=1).unsqueeze(1)+1e-5) \n        return self.attn(x, context, mask=mask) ","block_group":"557fd55e87514f859a8d595d53fe1365","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"d382939b419a4c39ad183842368f36ea","deepnote_cell_type":"code"},"source":"attnEmbd = nn.Sequential(\n    EmbeddingAttentionBag(VOCAB_SIZE, embed_dim, padding_idx=padding_idx), \n    nn.Linear(embed_dim, embed_dim),\n    nn.LeakyReLU(),\n    nn.BatchNorm1d(embed_dim),\n    nn.Linear(embed_dim, NUM_CLASS)\n)","block_group":"e5e7f4601ae245e58b0875e2ea4ca247","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"7ddd699d26374fb59e06a63a39caf9cd","deepnote_cell_type":"code"},"source":"attnEmbd_results = train_network(attnEmbd, \nloss_func, \ntrain_loader, \nval_loader=test_loader, \nscore_funcs={'Accuracy': accuracy_score}, \ndevice=device, \nepochs=epochs)","block_group":"35827c773d194bd9bdd046c9a514175c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"ff1760b814c0417c88e6f0687ad1a4c8","deepnote_cell_type":"code"},"source":"# GRU\nsns.lineplot(x='total time', y='val Accuracy', data=gru_results, label='GRU')\n\n# Average Embedding\nsns.lineplot(x='total time', y='val Accuracy', data=simpleEmbdAvg_results, label='Average Embedding')\n\n# Attention Embedding\nsns.lineplot(x='total time', y='val Accuracy', data=attnEmbd_results, label='Attention Embedding')","block_group":"7fccb917805f4993bcfedb92a36875ff","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":27,"fromCodePoint":0}],"cell_id":"5beae6b31816486886310616dd9f0aeb","deepnote_cell_type":"text-cell-h2"},"source":"## Pooling over Time & 1D CNNs","block_group":"8aa20ee4b7634c45a5301e3bfc3cd73f"},{"cell_type":"code","metadata":{"cell_id":"df489cfbc0db41c795b0c0d41c9fc0ad","deepnote_cell_type":"code"},"source":"def cnnLayer(in_size, out_size): \n    return nn.Sequential(\n        nn.Conv1d(in_size, out_size, kernel_size=k_size, padding=k_size//2),\n        nn.LeakyReLU(),\n        nn.BatchNorm1d(out_size))\n\nk_size = 3\ncnnOverTime = nn.Sequential(\n    nn.Embedding(VOCAB_SIZE, embed_dim, padding_idx=padding_idx), \n    LambdaLayer(lambda x : x.permute(0,2,1)), \n    cnnLayer(embed_dim, embed_dim),\n    cnnLayer(embed_dim, embed_dim),\n    nn.AvgPool1d(2), \n    cnnLayer(embed_dim, embed_dim*2),\n    cnnLayer(embed_dim*2, embed_dim*2),\n    nn.AvgPool1d(2), \n    cnnLayer(embed_dim*2, embed_dim*4),\n    cnnLayer(embed_dim*4, embed_dim*4),\n    nn.AdaptiveMaxPool1d(1), \n    nn.Flatten(), \n    nn.Linear(4*embed_dim, embed_dim),\n    nn.LeakyReLU(),\n    nn.BatchNorm1d(embed_dim),\n    nn.Linear(embed_dim, NUM_CLASS)\n)","block_group":"28b3b21b6017449fb119c52a1ad1567b","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"2ee05c79ae38484faaa160e1d3d2c7c1","deepnote_cell_type":"code"},"source":"cnn_results = train_network(cnnOverTime, \nloss_func, \ntrain_loader, \nval_loader=test_loader, \nscore_funcs={'Accuracy': accuracy_score}, \ndevice=device, \nepochs=epochs)","block_group":"41a2e4fc055740a9a65ff02d4a2703d8","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"82429f1c990546e7a8b694a97b194943","deepnote_cell_type":"code"},"source":"# GRU\nsns.lineplot(x='total time', y='val Accuracy', data=gru_results, label='GRU')\n\n# Average Embedding\nsns.lineplot(x='total time', y='val Accuracy', data=simpleEmbdAvg_results, label='Average Embedding')\n\n# Attention Embedding\nsns.lineplot(x='total time', y='val Accuracy', data=attnEmbd_results, label='Attention Embedding')\n\n# CNN Adaptative Pooling\nsns.lineplot(x='total time', y='val Accuracy', data=cnn_results, label='CNN Adaptive Pooling')\n\nplt.grid(True)\nplt.show()","block_group":"12256ec3d71e4ca8a345d2ecac7e590d","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":58,"fromCodePoint":0}],"cell_id":"2f7d195dc6ae4a5bb8826e89ff931fb1","deepnote_cell_type":"text-cell-h2"},"source":"## Positional Embedding Add Sequence Information to any Model","block_group":"6c5eaf42f7b045ab9427edef63b96b53"},{"cell_type":"code","metadata":{"cell_id":"23bbc5cabe49475bba1d43201b68db89","deepnote_cell_type":"code"},"source":"# Positional Range\nposition = np.arange(0, 100)\n\n# Sine Position\nsns.lineplot(position, np.sin(position), label=\"sin(position)\")\n\nplt.grid(True)\nplt.show()","block_group":"ea02ac8448354b2596c5e6fc93159495","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"2a9dbcb4af544cf8b764a24ace1f9413","deepnote_cell_type":"code"},"source":"# Positional Range\nposition = np.arange(0, 100)\n\n# Sine Position\nsns.lineplot(x=position, \ny=np.sin(position), \nlabel=\"sin(position)\")\n\n# Sine Position on 10th\nsns.lineplot(x=position, \ny=np.sin(position/10), \nlabel=\"sin(position/10)\")\n\nplt.grid(True)\nplt.show()","block_group":"c96e42ba6bb64227ae03bfc05362750b","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"dd91a6837b464fb884433d7ade4d620e","deepnote_cell_type":"code"},"source":"# Dimesionality\ndimensions = 6 \n\n# Positional Range\nposition = np.expand_dims(np.arange(0, 100), 1)\n\n# Frequency Stability\ndiv = np.exp(np.arange(0, dimensions*2, 2) * (-math.log(10000.0) / (dimensions*2)))\n\nfor i in range(dimensions):\n    sns.lineplot(x=position[:,0], y=np.sin(position*div)[:,i], label=\"Dim-\"+str(i))","block_group":"ed896c2b906b4837b28c2eb399d00e93","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":41,"fromCodePoint":0}],"cell_id":"2cc76faf6d2f4ca7bc462fcb2608c502","deepnote_cell_type":"text-cell-h3"},"source":"### Implementing a Positional Encoding Module","block_group":"11b60bcbabc04780acc748fe4ac1c18e"},{"cell_type":"code","metadata":{"cell_id":"1a8573d62e7b492a9a4cf82f630d1a59","deepnote_cell_type":"code"},"source":"class PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model, dropout=0.1, max_len=5000, batch_first=False):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        self.d_model = d_model\n\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)\n        self.register_buffer('pe', pe)\n        \n        self.batch_first = batch_first\n\n    def forward(self, x):\n        if self.batch_first: \n            x = x.permute(1, 0, 2)\n\n        x = x *np.sqrt(self.d_model) + self.pe[:x.size(0), :]\n        x = self.dropout(x)\n        \n        if self.batch_first: \n            x = x.permute(1, 0, 2)\n            \n        return x","block_group":"8070a16ffefe4d709332b01356bf1695","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"e8192a90bf0b49b1b96476fe12d7a402","deepnote_cell_type":"code"},"source":"simplePosEmbdAvg = nn.Sequential(\n    nn.Embedding(VOCAB_SIZE, embed_dim, padding_idx=padding_idx), \n    PositionalEncoding(embed_dim, batch_first=True),\n    nn.Linear(embed_dim, embed_dim),\n    nn.LeakyReLU(),\n    nn.Linear(embed_dim, embed_dim),\n    nn.LeakyReLU(),\n    nn.Linear(embed_dim, embed_dim),\n    nn.LeakyReLU(),\n    nn.AdaptiveAvgPool2d((1,None)), \n    nn.Flatten(), \n    nn.Linear(embed_dim, embed_dim),\n    nn.LeakyReLU(),\n    nn.BatchNorm1d(embed_dim),\n    nn.Linear(embed_dim, NUM_CLASS)\n)","block_group":"6f8ecbccc37f443d94021f8c7b5c5c2d","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"e6caf876960240f696120afdd21b8152","deepnote_cell_type":"code"},"source":"embd_layers =  nn.Sequential( \n    *([PositionalEncoding(embed_dim, batch_first=True)]+\n      [nn.Sequential(nn.Linear(embed_dim, embed_dim), nn.LeakyReLU()) for _ in range(3)])\n)\n\nattnPosEmbd = nn.Sequential(\n    EmbeddingAttentionBag(VOCAB_SIZE, embed_dim, padding_idx=padding_idx, embd_layers=embd_layers), #(B, T) -> (B, D) \n    nn.Linear(embed_dim, embed_dim),\n    nn.LeakyReLU(),\n    nn.BatchNorm1d(embed_dim),\n    nn.Linear(embed_dim, NUM_CLASS)\n)\n\nposEmbdAvg_results = train_network(simplePosEmbdAvg, \nloss_func, \ntrain_loader, \nval_loader=test_loader, \nscore_funcs={'Accuracy': accuracy_score}, \ndevice=device, \nepochs=epochs)","block_group":"e726d59642ce412c91d35fcad35093d3","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"a57986f27be24ee5b92ce3b31650c1d0","deepnote_cell_type":"code"},"source":"attnPosEmbd_results = train_network(attnPosEmbd, \nloss_func, \ntrain_loader, \nval_loader=test_loader, \nscore_funcs={'Accuracy': accuracy_score}, \ndevice=device, \nepochs=epochs)","block_group":"f07891b7bdbd453eb27c41bbacc96340","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":28,"fromCodePoint":0}],"cell_id":"a1ff44f106bb4b2b982aab9fa5c3a7b6","deepnote_cell_type":"text-cell-p"},"source":"Positional Encoding Results:","block_group":"45529f7ff5704d08a4f82e2d6d7e8b57"},{"cell_type":"code","metadata":{"cell_id":"24745bf2aa0c42758a915958bafde643","deepnote_cell_type":"code"},"source":"# Average Embedding\nsns.lineplot(x='total time', y='val Accuracy', data=simpleEmbdAvg_results, label='Average Embedding')\n\n# Average Positional Embedding\nsns.lineplot(x='total time', y='val Accuracy', data=posEmbdAvg_results, label='Average Positional Embedding')\n\n# Attention Embedding\nsns.lineplot(x='total time', y='val Accuracy', data=attnEmbd_results, label='Attention Embedding')\n\n# Attention Positional Embedding\nsns.lineplot(x='total time', y='val Accuracy', data=attnPosEmbd_results, label='Attention Positional Embedding')\n\nplt.grid(True)\nplt.show()","block_group":"6c20802a2b744fcc97ef958d8127500c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"d0801d2dd943407bb61b710f6b936d67","deepnote_cell_type":"code"},"source":"# GRU\nsns.lineplot(x='total time', \ny='val Accuracy', \ndata=gru_results, \nlabel='GRU')\n\n# Attention Embedding\nsns.lineplot(x='total time', \ny='val Accuracy', \ndata=attnEmbd_results, \nlabel='Attention Embedding')\n\n# Attention Positional Embedding\nsns.lineplot(x='total time', \ny='val Accuracy', \ndata=attnPosEmbd_results, \nlabel='Attention Positional Embedding')","block_group":"70795aa304144c89a56e7db2120b2267","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":37,"fromCodePoint":0}],"cell_id":"3b26ab7a6e3f41e7817b5f10e255765d","deepnote_cell_type":"text-cell-h2"},"source":"## Transformers: Big Models for Big Data","block_group":"dfef75adc0904fc4a034b720a374590d"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":19,"fromCodePoint":0}],"cell_id":"7a071b5c1ccf401b87dc398b12b4dd2c","deepnote_cell_type":"text-cell-h3"},"source":"### Multihead Attention","block_group":"ede5d374479d4972a3ecb763ed69b1c1"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":20,"fromCodePoint":0}],"cell_id":"005e47543d984a958b72ef9c9f189361","deepnote_cell_type":"text-cell-p"},"source":"Transformers Blocks:","block_group":"a7104ec7e7154d3cb3dd22091d6c8ff8"},{"cell_type":"code","metadata":{"cell_id":"e7ab482c6428418a8e4d48c3227dda40","deepnote_cell_type":"code"},"source":"class SimpleTransformerClassifier(nn.Module):\n\n    def __init__(self, vocab_size, D, padding_idx=None):\n        super(SimpleTransformerClassifier, self).__init__()\n        self.padding_idx = padding_idx\n        self.embd = nn.Embedding(vocab_size, D, padding_idx=padding_idx)\n        self.position = PositionalEncoding(D, batch_first=True)\n        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=D, nhead=8),num_layers=3)\n        self.attn = AttentionAvg(AdditiveAttentionScore(D))\n        self.pred = nn.Sequential(\n            nn.Flatten(), \n            nn.Linear(D, D),\n            nn.LeakyReLU(),\n            nn.BatchNorm1d(D),\n            nn.Linear(D, NUM_CLASS)\n        )\n    \n    def forward(self, input):\n        if self.padding_idx is not None:\n            mask = input != self.padding_idx\n        else:\n            mask = input == input \n        x = self.embd(input) \n        x = self.position(x)  \n        x = self.transformer(x.permute(1,0,2)) \n        x = x.permute(1,0,2) \n        context = x.sum(dim=1)/mask.sum(dim=1).unsqueeze(1)\n        return self.pred(self.attn(x, context, mask=mask))","block_group":"3de7f62919b544458eea919f3b079a1f","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"7328b5f2d45f4fcab1680ca69a5e2760","deepnote_cell_type":"code"},"source":"simpleTransformer = SimpleTransformerClassifier(VOCAB_SIZE, \nembed_dim, \npadding_idx=padding_idx)\n\ntransformer_results = train_network(simpleTransformer, \nloss_func, \ntrain_loader, \nval_loader=test_loader, \nscore_funcs={'Accuracy': accuracy_score}, \ndevice=device, \nepochs=epochs)","block_group":"057cdcd47bd8471886edb5eba94451d8","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1717426688293,"execution_millis":649,"deepnote_to_be_reexecuted":false,"cell_id":"c95d3e0fa8e8420da365f3e2ed25a335","deepnote_cell_type":"code"},"source":"# GRU\nsns.lineplot(x='total time', y='val Accuracy', data=gru_results, label='GRU')\n\n# Attention Embedding\nsns.lineplot(x='total time', y='val Accuracy', data=attnEmbd_results, label='Attention Embedding')\n\n# Attention Positional Embedding\nsns.lineplot(x='total time', y='val Accuracy', data=attnPosEmbd_results, label='Attention Positional Embedding')\n\n# CNN Adaptive Pooling\nsns.lineplot(x='total time', y='val Accuracy', data=cnn_results, label='CNN Adaptive Pooling')\n\n# Transformer\nsns.lineplot(x='total time', y='val Accuracy', data=transformer_results, label='Transformer')","block_group":"01db6cd6588440cdb44fac0044414571","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'sns' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mlineplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal time\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mgru_results, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGRU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal time\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mattnEmbd_results, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttention Embedding\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal time\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mattnPosEmbd_results, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttention Positional Embedding\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"]}],"outputs_reference":"s3:deepnote-cell-outputs-production/697c8055-47c8-4f7d-a140-77a45b992617","content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"d11dafe41508441881db0f6bdd85e4a9","deepnote_cell_type":"code"},"source":"","block_group":"6150c7463e354fbba71472feb53148a2","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=1d6ef229-9840-40af-b62b-b2ab55589447' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"18c5a1cadde843c9b4f3b6ccdea7ec6e","deepnote_execution_queue":[]}}